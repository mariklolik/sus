model:
  name: Qwen/Qwen2.5-1.5B
  use_lora: true
  lora_r: 8
  lora_alpha: 16

training:
  num_epochs: 3
  batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 2e-5
  max_length: 256
  num_trajectories: 8

sus:
  enabled: true
  strategy_dim: 128
  lambda_ss: 1.0
  lambda_sus: 0.0  # SS only
  alpha: 0.3

evaluation:
  num_samples: 200
  k_values: [1, 5, 10]
